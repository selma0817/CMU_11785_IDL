# Homework Archive for 11785 2024 Fall

## Introduction
Homework part 1 for autograd mytorch, Homework part 2 for Kaggle competition.

## Table of Contents
- [Introduction](#introduction)
- [HW1 MLP | Phoneme Recognition](#hw1-mlp--phoneme-recognition)
- [HW2 CNN | Face Recognition and Verification](#hw2-cnn--face-recognition-and-verification)
- [HW3 RNN | Automatic Speech Recognition (ASR)](#hw3-rnn--automatic-speech-recognition-asr)
- [HW4 Transformer | ASR](#hw4-transformer--asr)

## HW1 MLP | Phoneme Recognition

- **HW1P1**  
  Implement MLP layers, activations, losses, optimizers, and regularizations.

- **HW1P2**  
  MLP for frame level speech recognition.

## HW2 CNN | Face Recognition and Verification

- **HW2P1**  
  Implement convolutional layer, pooling layers, upsampling, downsampling, forward and backward pass of CNN.

- **HW2P2**  
  ConvNext/ResNet Face verification with evaluation metrics EER (Equal Error Rate).

## HW3 RNN | Automatic Speech Recognition (ASR)

- **HW3P1**  
  Implement RNN cells, GRU cells, CTC loss forward and backward pass, Greedy Search, and Beam Search.

- **HW3P2**  
  Automatic Speech Recognition (LibriSpeech ASR with Phonetic Transcription) with evaluation metrics of Levenshtein Distance.

## HW4 Transformer | ASR

- **HW4P1**  
  Implementing self-attention in `attention.py` and a language model with a custom dataloader.

- **HW4P2**  
  Building Automatic Speech Recognition using Transformer-based architecture. CER (Character Error Rate) as metrics.
