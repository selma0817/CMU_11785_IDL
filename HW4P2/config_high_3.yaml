Name                      : "yiyan"
###### Dataset -----------------------------------------------------------------
root                      : "/ix1/hkarim/yip33/kaggle_dataset/hw4_data/hw4p2"                # TODO: Set the root path of your data
unpaired_text_partition   : "text-for-LM"               # unpaired text for LM pre-training
train_partition           : "train-clean-100"           # train-clean-100
val_partition             : "dev-clean"                 # validation partition
test_partition            : "test-clean"                # test partition
NUM_WORKERS               : 2
subset                    : 1.0        # Load a subset of the data (for debugging, testing, etc)
token_type                : "1k"     # [char, 1k, 10k]
feat_type                 : 'fbank'    # ['fbank', 'mfcc']
num_feats                 : 70         # fbanks:[20-80], mfcc:[12:20]
batch_size                : 16
norm                      : 'cepstral' # ['global_mvn', 'cepstral']
###### SpecAugment ---------------------------------------------------------------
specaug                   : True
specaug_conf:
  apply_freq_mask         : True
  freq_mask_width_range   : 4
  num_freq_mask           : 2
  apply_time_mask         : True
  time_mask_width_range   : 10
  num_time_mask           : 6

###### Network Specs -------------------------------------------------------------
d_model                   : 256
d_ff                      : 2048

###### Embedding Specs -----------------------------------------------------------
time_stride               : 4 # time-wise downsampling
feature_stride            : 2 # feature-wise downsampling
embed_dropout             : 0.2

###### Encoder Specs -------------------------------------------------------------
enc_dropout               : 0.2
enc_num_layers            : 6
enc_num_heads             : 8

###### Decoder Specs -------------------------------------------------------------
dec_dropout               : 0.2
dec_num_layers            : 6
dec_num_heads             : 8

###### Base Parameters -----------------------------------------------------------
use_wandb                 : True
use_ctc                   : True
ctc_weight                : 0.5
optimizer                 : "AdamW" # Adam, AdamW, SGD
momentum                  : 0.0
nesterov                  : True
learning_rate             : 2E-4
scheduler                 : "CosineAnnealing" # ['ReduceLR', 'CosineAnnealing']
factor                    : 0.2
patience                  : 2
epochs                    : 300
pretrain_lm               : True
pretrain_encoder          : True
T_max                     : 50
resume_logging            : False
